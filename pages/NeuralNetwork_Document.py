import streamlit as st

st.title(":blue[NeuralNetwork Explanation]")

st.markdown("""### Dataset :green[Kaggle]""")
st.markdown("""#### ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Reference)
            https://www.kaggle.com/datasets/puneet6060/intel-image-classification/data""")
st.markdown("""‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ Dataset ‡∏ô‡∏µ‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô Image Processing ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡πÇ‡∏î‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡∏∞‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô 6 ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà... """)
code = '''
    classes = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']'''
st.code(code, language="python")

st.markdown("""
‡πÇ‡∏î‡∏¢‡∏°‡∏µ <span style="color:green"><b>‡∏Ç‡πâ‡∏≠‡∏î‡∏µ</b></span> ‡πÅ‡∏•‡∏∞ <span style="color:red"><b>‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢</b></span> ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

- <span style="color:green"><b>‡∏Ç‡πâ‡∏≠‡∏î‡∏µ</b></span>: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡∏∏‡∏î‡∏ù‡∏∂‡∏Å  
- <span style="color:red"><b>‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢</b></span>: ‡∏´‡∏≤‡∏Å‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô (Out-of-distribution data) ‡∏≠‡∏≤‡∏à‡∏™‡πà‡∏á‡∏ú‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á  
""", unsafe_allow_html=True)



st.text("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ import Intel Dataset")
code2 = '''
#Kaggle API
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#Download Dataset
!kaggle datasets download -d puneet6060/intel-image-classification

'''
st.code(code2, language="python")

refIMG = "https://www.kaggle.com/datasets/puneet6060/intel-image-classification/data"

col1, col2 = st.columns(2)
with col1 :
    st.image("intel_data/seg_test/seg_test/street/24052.jpg",caption=refIMG, width=350)
with col2 :
    st.image("intel_data/seg_test/seg_test/mountain/24066.jpg",caption=refIMG, width=350)

st.markdown(""" ### Model ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ :blue[Convolutional Neural Network (CNN)]""")

st.markdown(""" #### ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á CNN Model""")

st.text("Layers :")

col1, col2 = st.columns(2)
with col1 :
    st.image("image/LayerDetail.png")
with col2 :
    st.image("image/LayerCol.png")

st.markdown("""#### ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Preprocessing)
    ‡πÉ‡∏ä‡πâ ImageDataGenerator ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ Pixel (0-255 ‚Üí 0-1)
    ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 90% Train / 10% Validation       
    ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô 150x150 px""")

st.code("""
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train ‡πÅ‡∏•‡∏∞ Validation
train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)
train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=(150, 150), batch_size=32, class_mode="categorical", subset="training"
)
val_generator = train_datagen.flow_from_directory(
    train_dir, target_size=(150, 150), batch_size=32, class_mode="categorical", subset="validation"
)

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Test
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    test_dir, target_size=(150, 150), batch_size=32, class_mode="categorical", shuffle=False
)
""", language="python")

st.markdown("""#### ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Architecture & Compilation)""")

st.markdown("""
‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Ñ‡∏∑‡∏≠ **Convolutional Neural Network (CNN)** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û 6 ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà  
‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **3 ‡∏ä‡∏±‡πâ‡∏ô‡∏Ç‡∏≠‡∏á Convolutional Layers + MaxPooling** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û  
‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô Flatten ‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Fully Connected Layers ‡∏û‡∏£‡πâ‡∏≠‡∏° Dropout ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Overfitting  

### **üîπ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•**
- **Conv2D + ReLU** ‚Üí ‡∏î‡∏∂‡∏á Feature ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û
- **BatchNormalization** ‚Üí ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
- **MaxPooling2D** ‚Üí ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û
- **Flatten + Dense Layers** ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™
- **Softmax Output (6 Classes)** ‚Üí ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô 6 ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà

‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡∏î‡πâ‡∏ß‡∏¢ **Adam Optimizer** ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ **Categorical Crossentropy** ‡πÄ‡∏õ‡πá‡∏ô Loss Function  
‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡πâ‡∏ß‡∏¢ **Accuracy Metric**  
""")

st.code("""
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN
model = Sequential([
    Conv2D(32, (3,3), activation="relu", input_shape=(150, 150, 3)),
    BatchNormalization(),
    MaxPooling2D(2,2),
    
    Conv2D(64, (3,3), activation="relu"),
    BatchNormalization(),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation="relu"),
    BatchNormalization(),
    MaxPooling2D(2,2),
    
    Flatten(),
    Dense(256, activation="relu"),
    Dropout(0.5),
    
    Dense(6, activation="softmax")
])

# ‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

# ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÇ‡∏°‡πÄ‡∏î‡∏•
model.summary()
""", language="python")

st.markdown("""#### ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Training)""")

st.markdown("""
‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏ù‡∏∂‡∏Å‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **Train Set** ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡πâ‡∏ß‡∏¢ **Validation Set**  
‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **EarlyStopping** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏´‡∏≤‡∏Å `val_loss` ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á ‡πÅ‡∏•‡∏∞ **ReduceLROnPlateau**  
‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö Learning Rate ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏° Overfitting  

#### **üîπ ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å**
- **Epochs:** 30 ‡∏£‡∏≠‡∏ö (‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏≤‡∏Å `val_loss` ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á)
- **Optimizer:** Adam
- **Loss Function:** Categorical Crossentropy
- **Batch Size:** 32
- **Callbacks:** EarlyStopping & ReduceLROnPlateau

‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ  
""")

st.code("""
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Callback ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Overfitting
early_stopping = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=3, min_lr=1e-6)

# ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
history = model.fit(
    train_generator,
    epochs=30,
    validation_data=val_generator,
    callbacks=[early_stopping, reduce_lr]
)
""", language="python")

st.markdown("""#### ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• (Model Evaluation)""")
st.code("""
    test_loss, test_acc = model.evaluate(test_generator)
""", language="python")

st.image("image/evaluateModel.png")