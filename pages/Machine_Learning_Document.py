import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
from sklearn.cluster import KMeans, DBSCAN
from sklearn.model_selection import train_test_split


@st.cache_data
def load_data():
    file_path = "C:/Users/Acer/Desktop/IS_Project/factype2.xlsx" 
    return pd.read_excel(file_path)

df = load_data()

st.markdown("""### ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Loading)""")

st.markdown(""" 
‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ
""")

st.code("""
#load Dataset
@st.cache_data
def load_data():
    file_path = 'C:/Users/Acer/Desktop/IS_Project/factype2.xlsx'
    return pd.read_excel(file_path)

df = load_data()
""", language="python")

st.markdown("""
- **‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**: [data.go.th](https://data.go.th/dataset/factype2)  
""")

st.markdown("""
### ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
- **FID**: ‡∏£‡∏´‡∏±‡∏™‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
- **‡∏£‡∏´‡∏±‡∏™‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó**: ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à
- **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô**: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
- **‡∏õ‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**: ‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
- **‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°**: ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡πÄ‡∏á‡∏¥‡∏ô‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏Ç‡∏≠‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à (Feature ‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå)
- **‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤**: ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏¥‡∏ï‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (Feature ‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå)
""")

st.markdown("### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
st.dataframe(df.head())

st.markdown("""
- ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏ä‡πà‡∏ô **‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°** ‡πÅ‡∏•‡∏∞ **‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤** ‡∏°‡∏µ‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
""")

st.markdown("""### ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Preprocessing)""")

st.markdown("""
‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Machine Learning
""")

st.markdown("""
### ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (Missing Values)
""")

missing_data = df.isnull().sum()
st.write("**Missing Values in Dataset:**")
st.dataframe(missing_data)

st.markdown("""
### ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (Imputation)
‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ **Imputation** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏•‡∏á‡πÑ‡∏õ ‡πÇ‡∏î‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°:
- **‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Most Frequent)**
- **‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏°‡∏±‡∏ò‡∏¢‡∏ê‡∏≤‡∏ô (Median) ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (Mean)**
- **‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ** ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
""")

@st.cache_data
def impute_data(df):
    imputer = SimpleImputer(strategy="most_frequent")
    df[["‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°", "‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤"]] = imputer.fit_transform(df[["‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°", "‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤"]])
    return df

df = impute_data(df)

st.markdown("### ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç missing values")
st.dataframe(df.head())

st.markdown("""
### ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Scaling)
            ‡πÉ‡∏ä‡πâ **StandardScaler** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô 
""")

st.code('''scaler = StandardScaler()
scaled_data = scaler.fit_transform(df[["‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°", "‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤"]])''',language="python")

st.markdown("""
### K-MEANS
            K-Means ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Clustering)
‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏° (k) ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ô
""")

st.code('''kmeans = KMeans(n_clusters=k_value, random_state=42)
        kmeans_labels = kmeans.fit_predict(scaled_data)''',language="python")

st.markdown("""
### DBSCAN
    ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏µ‡∏Å‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    ‡∏ã‡∏∂‡πà‡∏á‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å K-Means ‡∏ï‡∏£‡∏á‡∏ó‡∏µ‡πà DBSCAN ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤
    ‡πÅ‡∏ï‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡πÅ‡∏ô‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏à‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏õ‡∏•‡∏Å‡∏õ‡∏•‡∏≠‡∏° (Outliers) ‡πÑ‡∏î‡πâ
""")

st.code('''dbscan = DBSCAN(eps=eps_value, min_samples=min_samples_value)
        dbscan_labels = dbscan.fit_predict(scaled_data)''',language="python")

scaler = StandardScaler()
scaled_data = scaler.fit_transform(df[["‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°", "‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤"]])

k_value = 3  
eps_value = 1.0
min_samples_value = 4  

kmeans = KMeans(n_clusters=k_value, random_state=42)
kmeans_labels = kmeans.fit_predict(scaled_data)
df["KMeans_Cluster"] = kmeans_labels

dbscan = DBSCAN(eps=eps_value, min_samples=min_samples_value)
dbscan_labels = dbscan.fit_predict(scaled_data)
df["DBSCAN_Cluster"] = dbscan_labels

st.markdown("""
## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° (Clustering) 
**‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ:**  
- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Cluster ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö K-Means: **3**  
- ‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á Epsilon ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DBSCAN: **1.0**  
- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏∏‡∏î‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡πÉ‡∏ô‡∏Ñ‡∏•‡∏±‡∏™‡πÄ‡∏ï‡∏≠‡∏£‡πå (Min Samples): **4**  
""")

st.markdown("## üîπ K-Means Visualization")

fig, ax = plt.subplots()
sns.scatterplot(x=df["‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°"], y=df["‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤"], hue=df["KMeans_Cluster"], palette="viridis", ax=ax)
ax.set_xlabel("Total Capital")
ax.set_ylabel("Horsepower")
ax.set_title("K-Means Clustering")
st.pyplot(fig)

st.markdown("""‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÅ‡∏¢‡∏Å ‡πÇ‡∏£‡∏á‡∏á‡∏≤‡∏ô ‡∏Ç‡∏ô‡∏≤‡∏î ‡πÄ‡∏•‡πá‡∏Å ‡∏Å‡∏•‡∏≤‡∏á ‡πÉ‡∏´‡∏ç‡πà""")

for i in range(k_value):
    cluster_data = df[df["KMeans_Cluster"] == i]
    min_funding = cluster_data["‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°"].min()
    max_funding = cluster_data["‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°"].max()
    min_hp = cluster_data["‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤"].min()
    max_hp = cluster_data["‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤"].max()

    st.write(f"**Cluster {i + 1}:**")
    st.write(f"- **Total Capital:** {min_funding} to {max_funding} Millions Bath")
    st.write(f"- **Horsepower:** {min_hp} to {max_hp}")
    st.write("---")

st.markdown("## üîπ DBSCAN Visualization")

fig, ax = plt.subplots()
sns.scatterplot(x=df["‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏∏‡∏ô‡∏£‡∏ß‡∏°"], y=df["‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤"], hue=df["DBSCAN_Cluster"], palette="coolwarm", ax=ax)
ax.set_xlabel("Total Capital")
ax.set_ylabel("Horsepower")
ax.set_title("DBSCAN Clustering")
st.pyplot(fig)

st.markdown("""‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà""")

outliers_dbscan = df[df["DBSCAN_Cluster"] == -1]
if len(outliers_dbscan) > 0:
    st.error(f"‚ö†Ô∏è ‡∏û‡∏ö Outliers ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: {len(outliers_dbscan)} ‡∏à‡∏∏‡∏î")
else:
    st.success("‚úÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö Outliers ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")